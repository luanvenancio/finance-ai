{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJelH_H0qYSA"
      },
      "outputs": [],
      "source": [
        "!pip install ta\n",
        "\n",
        "import ta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iv8fqg7P-bd"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Extraction"
      ],
      "metadata": {
        "id": "c-rLcypHZZYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-GZaoxnytCc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1111)\n",
        "\n",
        "df = pd.read_csv('Database.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA5Dq1iYAxb4"
      },
      "outputs": [],
      "source": [
        "dataDates = pd.to_datetime(df['Date'], errors='coerce')\n",
        "\n",
        "df[\"year\"] =  dataDates.dt.year\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OChN30zTscf1"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taAMk2BS041G"
      },
      "source": [
        "### Time Series Feature\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHPQO23bsFS_"
      },
      "outputs": [],
      "source": [
        "open = df.Open\n",
        "high = df.High\n",
        "low = df.Low\n",
        "close = df.Close\n",
        "volume = df.Volume"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Close Lag Feature\n",
        "df['Close_Lag_1'] = close.shift(1)\n",
        "\n",
        "# Volume difference\n",
        "df['Volume_diff'] = volume.diff()\n",
        "\n",
        "# Volume Weighted Average Price\n",
        "df['vwap'] = (close * volume).cumsum() / volume.cumsum()\n",
        "\n",
        "# Volume Percentage Change\n",
        "df['volume_percentage_change'] = volume.pct_change()\n",
        "\n",
        "# Daily Return\n",
        "df['daily_Return'] = close.pct_change() * 100"
      ],
      "metadata": {
        "id": "Q2pNvLzGQeax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn3RRCIjDY3u"
      },
      "outputs": [],
      "source": [
        "interators = [2, 3, 4, 5, 10]\n",
        "\n",
        "for interator in interators:\n",
        "\n",
        "    # Lag Feature\n",
        "    close_lag_column = f\"Close_Lag_{interator}\"\n",
        "    df[close_lag_column] = close.shift(interator)\n",
        "\n",
        "    # Rolling Avg\n",
        "    rolling_averages = df.rolling(interator).mean()\n",
        "    close_rolling_mean_column = f\"Close_Rolling_Mean_{interator}\"\n",
        "    df[close_rolling_mean_column] = rolling_averages[\"Close\"]\n",
        "\n",
        "    # Close Ratio\n",
        "    close_ratio_column = f\"Close_Ratio_{interator}\"\n",
        "    df[close_ratio_column] = close / rolling_averages[\"Close\"]\n",
        "\n",
        "    # Rolling Standard Deviation\n",
        "    rolling_std = df.rolling(interator).std()\n",
        "    close_rolling_std_column = f\"Close_Rolling_Std_{interator}\"\n",
        "    df[close_rolling_std_column] = rolling_std[\"Close\"]\n",
        "\n",
        "    # Expanding Avg\n",
        "    expanding_averages = df.expanding(interator).mean()\n",
        "    close_expanding_mean_column = f\"Close_Expanding_Mean_{interator}\"\n",
        "    df[close_expanding_mean_column] = expanding_averages[\"Close\"]\n",
        "\n",
        "    # Expanding Standard Deviation\n",
        "    expanding_std = df.expanding(interator).std()\n",
        "    close_expanding_std_column = f\"Close_Expanding_Mean_{interator}\"\n",
        "    df[close_expanding_std_column] = expanding_std[\"Close\"]\n",
        "\n",
        "    # Exponential Moving Avg\n",
        "    exponential_mov_avg = df.ewm(span=interator, adjust=False).mean()\n",
        "    exponential_moving_avg_column = f\"Exponential_Moving_Avg_{interator}\"\n",
        "    df[exponential_moving_avg_column] = exponential_mov_avg[\"Close\"]\n",
        "\n",
        "    # Simple Moving Average\n",
        "    sma = df.rolling(interator).mean()\n",
        "    sma_mean_column = f\"sma_{interator}\"\n",
        "    df[sma_mean_column] = sma[\"Close\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVMuQSVJ2Y46"
      },
      "outputs": [],
      "source": [
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49vjOte91LE5"
      },
      "source": [
        "### Technical Indicator Feature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving Average Convergence Divergence (MACD)\n",
        "df['MACD'] = ta.trend.macd_diff(df['Close'])\n",
        "\n",
        "# Relative Strength Index (RSI)\n",
        "df['RSI_5'] = ta.momentum.rsi(df['Close'], window=5)\n",
        "df['RSI_14'] = ta.momentum.rsi(df['Close'], window=14)\n",
        "\n",
        "# Money Flow Multiplier: [(Close - Low) - (High - Close)] /(High - Low)\n",
        "money_flow_mult = ((close - low) - (high - close)) /(high - low)\n",
        "df['money_flow_mult'] = money_flow_mult\n",
        "\n",
        "# Money Flow Volume: Money Flow Multiplier x Volume for the Period\n",
        "money_flow_volume = money_flow_mult * volume\n",
        "df['money_flow_volume'] = money_flow_volume\n",
        "\n",
        "# ADL(ADI): Previous ADL + Current Period's Money Flow Volume\n",
        "adi = money_flow_volume.cumsum()\n",
        "df['adi'] = adi\n",
        "\n",
        "# Chaikin Money Flow\n",
        "cmf = money_flow_volume.rolling(20).sum() / volume.rolling(20).sum()\n",
        "df['chaikin_money_flow'] = cmf\n",
        "\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wFnHIL2UFbQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6W4LmWWsjb_"
      },
      "source": [
        "## Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y20_K4PB6OQF"
      },
      "outputs": [],
      "source": [
        "y_test_aux = df.loc[df['year'] >= 2022, ['Date', 'Output']].reset_index()\n",
        "\n",
        "y_train = df.loc[df['year'] < 2022, 'Output']\n",
        "X_train = df.loc[df['year']  < 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")\n",
        "\n",
        "y_test = df.loc[df['year']  >= 2022, 'Output']\n",
        "X_test = df.loc[df['year']  >= 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPzAHh1HrefY"
      },
      "source": [
        "## Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu6PzhD6gPPb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Aplica Random Forest Classification para o conjunto de treinamento\n",
        "classifier = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1111)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predição com os o conjunto de teste\n",
        "y_pred = classifier.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk6w4EUw50aC"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfS2dSrqq_GP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score, precision_score, accuracy_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def evaluate_classification(y_test, y_pred):\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  AUC = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"AUC:\", AUC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfddfOm1pHCA"
      },
      "outputs": [],
      "source": [
        "evaluate_classification(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox7ntUgssiqV"
      },
      "source": [
        "## Generate Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5G2RD2ApmZW"
      },
      "outputs": [],
      "source": [
        "def generate_output(y_test, y_pred):\n",
        "  date = df.loc[df['year'] >= 2022, ['Date', 'Output']].reset_index()\n",
        "  date = pd.to_datetime(date['Date']).dt.strftime('%Y%m%d')\n",
        "  date = pd.DataFrame(date)\n",
        "\n",
        "  pred = pd.DataFrame(y_pred, columns = ['Prediction'])\n",
        "\n",
        "  output = pd.concat([date, pred], axis=1)\n",
        "  output.to_csv('output.csv', index=False)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(y_test,y_pred)"
      ],
      "metadata": {
        "id": "jlXY--RQPF0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJO1b5rUrrxA"
      },
      "source": [
        "## Time Series Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwSHMRKSe5Su"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def expanding_window(model, X_train, y_train, window_size):\n",
        "\n",
        "    pred = []\n",
        "    actuals = []\n",
        "\n",
        "    size = len(df.loc[df['year'] < 2022].index)\n",
        "    size_max =  len(df)\n",
        "\n",
        "    train_starts = range(size, size_max, window_size)\n",
        "    i = 0\n",
        "\n",
        "    for train_start in train_starts:\n",
        "\n",
        "        X_train_window, X_test_window = X_train[:train_start], X_train[train_start : train_start + window_size]\n",
        "        y_train_window, y_test_window = y_train[:train_start], y_train[train_start : train_start + window_size]\n",
        "\n",
        "        print(f\"Fold: {i}\")\n",
        "        #print(f\"Train: index={X_train[:train_start].index} - Size: {X_train[:train_start].size}\")\n",
        "        #print(f\"Test:  index={y_train[train_start : train_start + window_size].index} - Size: {y_train[train_start : train_start + window_size].size} \\n\")\n",
        "\n",
        "        model.fit(X_train_window, y_train_window)\n",
        "        y_pred_window = model.predict(X_test_window)\n",
        "\n",
        "        i+=1\n",
        "        pred.extend(y_pred_window)\n",
        "        actuals.extend(y_test_window)\n",
        "\n",
        "    return np.array(pred), np.array(actuals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7SmjnBegw4S"
      },
      "outputs": [],
      "source": [
        "y = df['Output']\n",
        "X = df.drop(['Output', 'Return', 'Date'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gy1CufSbPlb"
      },
      "source": [
        "### Time Series Split (22 Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_hlztVPrxWA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(classifier, X, y, window_size=22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSjMzVPIQX43"
      },
      "outputs": [],
      "source": [
        "evaluate_classification(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "s9uUNAGIMo0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INfbPi4Kbb30"
      },
      "source": [
        "### Time Series Split (5 Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVbllw0jbb39"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(classifier, X, y, window_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OPrS0-0bb4A"
      },
      "outputs": [],
      "source": [
        "evaluate_classification(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDyhFa6yeddc"
      },
      "outputs": [],
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZmDlA2Gbqpf"
      },
      "source": [
        "### Time Series Split (1 Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R01UZ4clbqpl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(classifier, X, y, window_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGI7SiJIbqpo"
      },
      "outputs": [],
      "source": [
        "evaluate_classification(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "fPp8Y5-EM56y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY8Y5xzd0tWI"
      },
      "source": [
        "## Baseline Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvMSRM1Q0wF_"
      },
      "outputs": [],
      "source": [
        "y_train = df.loc[df['year'] < 2022, 'Output']\n",
        "X_train = df.loc[df['year'] < 2022].drop(['Output', 'Return'], axis=\"columns\")\n",
        "\n",
        "y_test = df.loc[df['year'] >= 2022, 'Output']\n",
        "X_test = df.loc[df['year'] >= 2022].drop(['Output', 'Return'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xDO5EWY0_J2"
      },
      "outputs": [],
      "source": [
        "y_pred_base_classifier = pd.DataFrame(y_test)\n",
        "y_pred_base_classifier.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnt7R7WZ1iJd"
      },
      "outputs": [],
      "source": [
        "y_pred_base_classifier['Output'] = 1\n",
        "y_pred_base_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx481yC71zAh"
      },
      "outputs": [],
      "source": [
        "evaluate_classification(y_test, y_pred_base_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVc2dlqkMmN2"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJKe-X7GIJKT"
      },
      "outputs": [],
      "source": [
        "y_test_aux = df.loc[df['year'] >= 2022, ['Date', 'Output']].reset_index()\n",
        "\n",
        "y_train = df.loc[df['year'] < 2022, 'Return']\n",
        "X_train = df.loc[df['year']  < 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")\n",
        "\n",
        "y_test = df.loc[df['year'] >= 2022, 'Return']\n",
        "X_test = df.loc[df['year'] >= 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E67ayVgqodf"
      },
      "source": [
        "## Holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc95FxkHH-L9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def evaluate_regressor(y_test, y_pred):\n",
        "  test_set_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "  print('RMSE = ', test_set_rmse)\n",
        "\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  print(\"MAE = \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PMvidW7Ithk"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr3Dz99BH0Qn"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Aplica MLP para o conjunto de treinamento\n",
        "regressor = MLPRegressor(random_state=1111)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predição com os o conjunto de teste\n",
        "y_pred = regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia\n",
        "evaluate_regressor(y_test, y_pred)"
      ],
      "metadata": {
        "id": "nL9S0peguUMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWomP2ktKhcd"
      },
      "outputs": [],
      "source": [
        "generate_output(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-FvFH1MqUSB"
      },
      "source": [
        "## Time Series Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BRw-shHqSWA"
      },
      "outputs": [],
      "source": [
        "y = df['Return']\n",
        "X = df.drop(['Output', 'Return', 'Date'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqs9X9JWpwr-"
      },
      "source": [
        "### Time Series Split (22 Days)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "GLuR3vHNGo9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J63-GJGbp3T9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "regressor = MLPRegressor(hidden_layer_sizes=(1), max_iter=100, random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(regressor, X, y, window_size=22)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqW9jSDIrmrv"
      },
      "outputs": [],
      "source": [
        "evaluate_regressor(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCmE2EyAKr8E"
      },
      "outputs": [],
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3L5tla5qdT4"
      },
      "source": [
        "### Time Series Split (5 Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdZZcydTqaUz"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "regressor = MLPRegressor(random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(regressor, X, y, window_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_regressor(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "K7W2HPBzvv8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "xyjxHAbqzaEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcITIglYqgXD"
      },
      "source": [
        "### Time Series Split (1 Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTSZ3Ojkqjuz"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "regressor = MLPRegressor(random_state=1111)\n",
        "y_pred_window, y_test_window = expanding_window(regressor, X, y, window_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_regressor(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "FYo6z_TPCHJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_output(y_test_window, y_pred_window)"
      ],
      "metadata": {
        "id": "GRA2Al5NCJo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZTdjVuuaDqf"
      },
      "source": [
        "## Baseline Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxBBuO_r0mHQ"
      },
      "outputs": [],
      "source": [
        "y_test_aux = df.loc[df['year'] >= 2022, ['Date', 'Output']].reset_index()\n",
        "\n",
        "y_train = df.loc[df['year'] < 2022, 'Output']\n",
        "X_train = df.loc[df['year']  < 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")\n",
        "\n",
        "y_test = df.loc[df['year'] >= 2022, 'Return']\n",
        "X_test = df.loc[df['year'] >= 2022].drop(['Output', 'Return', 'Date'], axis=\"columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED1Q4g3HZr1A"
      },
      "outputs": [],
      "source": [
        "y_pred_base_regressor = pd.DataFrame(y_test).shift(1, fill_value=0)\n",
        "y_pred_base_regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKRu_1870fDv"
      },
      "outputs": [],
      "source": [
        "evaluate_regressor(y_test, y_pred_base_regressor)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c-rLcypHZZYA",
        "taAMk2BS041G",
        "49vjOte91LE5",
        "l6W4LmWWsjb_",
        "YPzAHh1HrefY",
        "dk6w4EUw50aC",
        "-dlUexgnr6tw",
        "ox7ntUgssiqV",
        "VY8Y5xzd0tWI"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}